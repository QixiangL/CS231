# Lecture2: Image Classification

Notes from QixiangL, 2019 May.19th
* Video: https://www.youtube.com/watch?v=OoUX-nOEjG0&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=2
* Slides: http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture2.pdf

# 0. Image Classification Overall
## 0.1 An Image Classifier
   * Given a set of images and set of discrete labels
   * Python API (quite brute and non-scalable):snake:
   ```python
   def classify_image(image):
   	# Some magic there?
	return class_label
   ```
## 0.2 Semantic Gap between human-vision and computer-vision
   * Human: high-level features
   * **Computer: low-level features** <br />
   	A gigantic grid of numbers between [0, 255] for each pixel (e.g. 800x600x3 for 3 channels RGB)
## 0.3 Challenges
   * Viewpoint variation: all pixel change when we change the camera
   * Illumination: dark & light
   * Deformation: tunned features, cats are liquid :ocean:
   * Occlusion: parts of the feature, cats are smart :100:
   * Background: difficult to detect the task from the background
   * Intraclass variance: difference between *orange* and *black* cats
## 0.4 Data-Driven Approach
   * Collect a dataset of images and labels
   * Use Machine Learning to train a classifier
   * Evaluate the classifier on new images
   * Python API:snake:
   ```python
   def train(images, labels):
   """Memorize all data and labels"""
   	# Machine learning!
	return model
	
   def predict(model, test_images)
   """Predict on test images"""
   	# Use model to predict labels
	return test_labels
   ```

# 1. Nearest Neighbor Model
*  Two step programming:
   - Memorize all data and labels
   - Predict the label of the most similar training image
*  **ggn** *(70-80s)*
	- [1]. Ggy
	- [2]. *Dag 1987* - Lg
* **Hghsgdel** *(Dagh)*
	- comg
* **Imgge** *(gnow)*
	- 2ghm
	   - 20g

# 2. Cjw
## 2.1 Whjjkt
   * Plj
	   - obghing, ...
## 2.2 Conj
   * Cggh
	   - YehjC
   * Whhj
	   - Chj
	   - *[Reason1] fashw* <br />
	   	(i.e. hU)
## 2.4 Phh
   * Prh: sasa
   	   - e.g. lihc

 
